mkdir caffe
cd caffe

cat > caffe-Dockerfile <<- 'EOF'
FROM ppc64le/centos-cuda-devel:8.0  
MAINTAINER Junli Zhang <junlizh@cn.ibm.com>

RUN \
  yum -y update && \
  yum -y install \
    unzip make cmake openblas-devel protobuf-devel snappy-devel opencv-devel boost-devel numpy \
    python-devel gflags-devel glog-devel lmdb-devel leveldb-devel hdf5-devel openmpi-devel && \
    ln -s /usr/include/openmpi-ppc64le /usr/lib64/openmpi/include && \
  rm -rf /var/cache/yum/* 

RUN \
  wget -c ftp://172.16.15.29/cuda/nccl/v1.3.4-1.zip && \
  unzip v1.3.4-1.zip && rm -f v1.3.4-1.zip && \
  cd nccl-1.3.4-1 && \
  sed -i -e 's:$(PREFIX)/lib:$(PREFIX)/lib64:g' Makefile && \
  MPI_HOME=/usr/lib64/openmpi make && \
  make PREFIX=/usr/local/cuda install

RUN \
  wget -c ftp://172.16.15.29/hpc/caffe/caffe-0.15.zip && \
  unzip caffe-0.15.zip && rm -f caffe-0.15.zip && \
  cd caffe-caffe-0.15 && \
  mkdir build && \
  cd build && \
  sed -i.ori "$[$(grep -n 'if(UNIX OR APPLE)' ../CMakeLists.txt | cut -f1 -d':')+1]a \  add_definitions(-D__STDC_LIMIT_MACROS)" ../CMakeLists.txt && \
  sed -i.ori 's:\(.*boost/thread/latch.hpp.*\):/\*\1\*/:g' ../src/caffe/parallel.cpp && \
  sed -i.ori "$[$(grep -n pause ../3rdparty/cub/host/mutex.cuh|cut -f1 -d':')-1]a \         #if defined(__powerpc64__) || defined(__powerpc__)\n                asm volatile(\"or 27,27,27\\\n\": : :\"memory\");\n         #else" ../3rdparty/cub/host/mutex.cuh && \
  sed -i "$[$(grep -n pause ../3rdparty/cub/host/mutex.cuh|cut -f1 -d':')]a \         #endif" ../3rdparty/cub/host/mutex.cuh && \
  sed -i.ori 's:\(set(Caffe_known_gpu_archs.*\)".*"\().*\):\1"30 37 50 52 60 61"\2:g' ../cmake/Cuda.cmake && \
  cmake .. \
  -DCMAKE_C_COMPILER=gcc \
  -DCMAKE_CXX_COMPILER=g++ \
  -DCMAKE_C_FLAGS="-O3" \
  -DCMAKE_CXX_FLAGS="-O3 -I$PWD/../3rdparty" \
  -DBLAS=open \
  -DUSE_CUDNN=on \
  -DUSE_NCCL=ON \
  -DNCCL_INCLUDE_DIR=/usr/local/cuda/include \
  -DNCCL_LIBRARY=/usr/local/cuda/lib64/libnccl.so \
  -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda \
  -DCMAKE_VERBOSE_MAKEFILE=on \
  -DCMAKE_INSTALL_PREFIX=/usr/local/caffe-nv && \
  make -j8 && \
  make install

#VERSION fp16 DO NOT SUPPORT NCCL
RUN \
  wget -c ftp://172.16.15.29/hpc/caffe/fp16.zip && \
  unzip fp16.zip && rm -f fp16.zip && \
  cd caffe-experimental-fp16 && \
  mkdir build && \
  cd build && \
  sed -i.ori "$[$(grep -n 'if(UNIX OR APPLE)' ../CMakeLists.txt | cut -f1 -d':')+1]a \  add_definitions(-D__STDC_LIMIT_MACROS)" ../CMakeLists.txt && \
  sed -i.ori "$[$(grep -n pause ../3rdparty/cub/cub/host/spinlock.cuh|cut -f1 -d':')-1]a \         #if defined(__powerpc64__) || defined(__powerpc__)\n                asm volatile(\"or 27,27,27\\\n\": : :\"memory\");\n         #else" ../3rdparty/cub/cub/host/spinlock.cuh && \
  sed -i "$[$(grep -n pause ../3rdparty/cub/cub/host/spinlock.cuh|cut -f1 -d':')]a \         #endif" ../3rdparty/cub/cub/host/spinlock.cuh && \
  sed -i.ori 's:\(set(Caffe_known_gpu_archs.*\)".*"\().*\):\1"30 37 50 52 60 61"\2:g' ../cmake/Cuda.cmake && \
  cmake .. \
  -DCMAKE_C_COMPILER=gcc \
  -DCMAKE_CXX_COMPILER=g++ \
  -DCMAKE_C_FLAGS="-O3" \
  -DCMAKE_CXX_FLAGS="-O3 -I$PWD/../3rdparty" \
  -DBLAS=open \
  -DUSE_CUDNN=on \
  -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda \
  -DCMAKE_VERBOSE_MAKEFILE=on \
  -DCMAKE_INSTALL_PREFIX=/usr/local/caffe-nv-fp16 && \
  make -j8 && \
  make install
EOF

docker build -t ppc64le/nvcaffe:0.15 -f caffe-Dockerfile  .

cd /dev/shm
wget -c ftp://172.16.15.29/hpc/caffe/ILSVRC2012_img.squashfs
unsquashfs ILSVRC2012_img.squashfs
rm -f ILSVRC2012_img.squashfs

mkdir -p ilsvrc12
cd ilsvrc12
wget -c ftp://172.16.15.29/hpc/RTHPC/caffe_ilsvrc12.tar.gz -O - | tar -xzf -
cd ..

wget -c ftp://172.16.15.29/hpc/caffe/caffe-0.15.zip
unzip caffe-0.15.zip
rm -f caffe-0.15.zip
mv caffe-caffe-0.15/examples/imagenet imagenet
rm -rf caffe-caffe-0.15
cat > prepare_lmdb.sh << 'EOF'
datadir=/data/squashfs-root
sed -i \
  -e 's:RESIZE=false:RESIZE=true:g' \
  -e "s:TRAIN_DATA_ROOT=.*:TRAIN_DATA_ROOT=${datadir}/train/:g" \
  -e "s:VAL_DATA_ROOT=.*:VAL_DATA_ROOT=${datadir}/val/:g" \
examples/imagenet/create_imagenet.sh
bash -x examples/imagenet/create_imagenet.sh
EOF
nvidia-docker run --rm -ti \
  -v /dev/shm/squashfs-root:/data/squashfs-root \
  -v /dev/shm/ilsvrc12:/caffe-caffe-0.15/data/ilsvrc12 \
  -v /dev/shm/imagenet:/caffe-caffe-0.15/examples/imagenet \
  -v /dev/shm/prepare_lmdb.sh:/caffe-caffe-0.15/prepare_lmdb.sh \
  -w /caffe-caffe-0.15 \
  ppc64le/nvcaffe:0.15 \
  bash /caffe-caffe-0.15/prepare_lmdb.sh

# wget -c ftp://172.16.15.29/hpc/caffe/AlexNet.lmdb.squashfs -O /dev/shm/AlexNet.lmdb.squashfs
# cd /dev/shm && unsquashfs AlexNet.lmdb.squashfs && rm -f AlexNet.lmdb.squashfs && mv /dev/shm/squashfs-root/* /dev/shm/

cat > run.sh <<- 'EOF'
sed -i -e 's|stepsize:.*|stepsize: 45000|g' models/bvlc_alexnet/solver.prototxt
sed -i -e 's|batch_size: 256|batch_size: 1024|g' models/bvlc_alexnet/train_val.prototxt
#IF GPU MEM capcity is not enough then change batch_size to 512
#sed -i -e 's|batch_size: 256|batch_size: 512|g' models/bvlc_alexnet/train_val.prototxt
#TOP1 validation
/usr/local/caffe-nv/bin/caffe train \
  --solver=models/bvlc_alexnet/solver.prototxt \
  --gpu all
EOF
nvidia-docker run --rm -ti \
  -v /dev/shm/squashfs-root:/data/squashfs-root \
  -v /dev/shm/ilsvrc12:/caffe-caffe-0.15/data/ilsvrc12 \
  -v /dev/shm/imagenet:/caffe-caffe-0.15/examples/imagenet \
  -v /dev/shm/run.sh:/caffe-caffe-0.15/run.sh \
  -w /caffe-caffe-0.15 \
  -e LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \
  ppc64le/nvcaffe:0.15 \
  bash /caffe-caffe-0.15/run.sh 2>&1 | tee  log-alexnet-nv-ppc-top1
cat log-alexnet-nv-ppc-top1|grep -E 'Iteration.*Testing net|accuracy'

cat > run.sh <<- 'EOF'
sed -i -e 's|stepsize:.*|stepsize: 45000|g' /caffe-caffe-0.15/models/bvlc_alexnet/solver.prototxt
sed -i -e 's|batch_size: 256|batch_size: 1024|g' /caffe-caffe-0.15/models/bvlc_alexnet/train_val.prototxt
#IF GPU MEM capcity is not enough then change batch_size to 512
#sed -i -e 's|batch_size: 256|batch_size: 512|g' /caffe-caffe-0.15/models/bvlc_alexnet/train_val.prototxt
#TOP5 validation
cat >> /caffe-caffe-0.15/models/bvlc_alexnet/train_val.prototxt << TOP5
layer {
  name: "accuracy/top-5"
  type: "Accuracy"
  bottom: "fc8"
  bottom: "label"
  top: "accuracy/top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
TOP5
/usr/local/caffe-nv/bin/caffe train \
  --solver=models/bvlc_alexnet/solver.prototxt \
  --gpu all
EOF
nvidia-docker run --rm -ti \
  -v /dev/shm/squashfs-root:/data/squashfs-root \
  -v /dev/shm/ilsvrc12:/caffe-caffe-0.15/data/ilsvrc12 \
  -v /dev/shm/imagenet:/caffe-caffe-0.15/examples/imagenet \
  -v /dev/shm/run.sh:/caffe-caffe-0.15/run.sh \
  -w /caffe-caffe-0.15 \
  -e LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \
  ppc64le/nvcaffe:0.15 \
  bash /caffe-caffe-0.15/run.sh 2>&1 | tee  log-alexnet-nv-ppc-top5
cat log-alexnet-nv-ppc-top5|grep -E 'Iteration.*Testing net|accuracy'

# If /usr/local/cuda/lib64/stubs add to LD_LIBRARY_PATH then when running application link with nvml it will says:
# 
# You should always run with libnvidia-ml.so that is installed with your
# NVIDIA Display Driver. By default it's installed in /usr/lib and /usr/lib64.
# libnvidia-ml.so in GDK package is a stub library that is attached only for
# build purposes (e.g. machine that you build your application doesn't have
# to have Display Driver installed).
# 
# http://stackoverflow.com/questions/17791053/cannot-run-cuda-code-that-queries-nvml-error-regarding-libnvidia-ml-so#comment25956032_17792017

nvidia-docker run --rm -ti \
  -v /dev/shm/squashfs-root:/data/squashfs-root \
  -v /dev/shm/ilsvrc12:/caffe-caffe-0.15/data/ilsvrc12 \
  -v /dev/shm/imagenet:/caffe-caffe-0.15/examples/imagenet \
  -v /dev/shm/run.sh:/caffe-caffe-0.15/run.sh \
  -w /caffe-caffe-0.15 \
  -e LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \
  ppc64le/nvcaffe:0.15 \
  /usr/local/caffe-nv-fp16/bin/caffe train \
  --solver=models/bvlc_alexnet/solver.prototxt \
  --gpu all 2>&1 | tee log-alexnet-nv-ppc-fp16
cat log-alexnet-nv-ppc-fp16|grep -E 'Iteration.*Testing net|accuracy'
